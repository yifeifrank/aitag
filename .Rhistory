}
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- c("Apple", "Tomato", "Broccoli")
annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?")
?tag_pplx
?tag_gpt
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- c("Apple", "Tomato", "Broccoli")
my_data <- c("Apple", "Tomato", "Broccoli")
annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?",storage = FALSE)
#' @examples
#' \dontrun{
#' my_data <- c("Apple", "Tomato", "Broccoli")
#' annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?")
#' }
#' @importFrom httr2 request req_headers req_body_json req_timeout req_perform resp_body_json
#' @importFrom stringr str_c str_replace_all
#' @importFrom dplyr if_else
#' @importFrom utils write.csv
#' @export
tag_gpt <- function(user_prompt,
sys_prompt = "",
temperature = 0,
api_key = base::Sys.getenv("openai_key"),
api_url = base::Sys.getenv("openai_url"),
model = "gpt-3.5-turbo-0125",
verbose = TRUE,
storage = TRUE) {
# Ensure the API URL is complete
api_url <- stringr::str_c(api_url, "/v1/chat/completions")
# Add filepath for output
columnname <- base::deparse(base::substitute(user_prompt))
filepath0 <- stringr::str_c("llm_output/", columnname, "/")
if (!base::dir.exists(filepath0)) {
base::dir.create(filepath0, recursive = TRUE)
}
filepath <- stringr::str_c(filepath0, model, ".csv")
base::print(base::paste("Writing CSV file to:", filepath))
# Function to process each text entry
annotate_text <- function(text, index, total) {
to_annotate_text <- stringr::str_replace_all(text, "(\n|\r)", " ")
authorization <- dplyr::if_else(api_url == "https://api.openai.com/v1/chat/completions", api_key, base::paste0("Bearer ", api_key))
attempt <- 1
max_attempts <- 3
success <- FALSE
result <- NA_character_
while (!success && attempt <= max_attempts) {
base::Sys.sleep(0.6) # Sleep to avoid rate limiting
tryCatch({
response <- httr2::request(api_url) |>
httr2::req_headers(`Content-Type` = "application/json", `Authorization` = authorization) |>
httr2::req_body_json(list(
model = model,
temperature = temperature,
messages = list(
list(role = "system", content = sys_prompt),
list(role = "user", content = to_annotate_text)
)
)) |>
httr2::req_timeout(60000) |> # 60 seconds timeout
httr2::req_perform()
if (response$status_code < 400) {
response_content <- httr2::resp_body_json(response)
result <- response_content$choices[[1]]$message$content
success <- TRUE
if (verbose) base::message("status_id: ", index, " of ", total, "\n", "sys_prompt: ", sys_prompt, "\n", "user_prompt: ", to_annotate_text)
if (verbose) base::message("ChatGPT: ", result, "\n")
} else {
# Capture and return the error message from the response
error_content <- httr2::resp_body_json(response)
result <- error_content$error$message
if (verbose) base::message(base::paste("Error annotating text", index, ":", result))
break
}
}, error = function(e) {
if (verbose) base::message(base::paste("Error on text", index, ":", e$message))
})
if (!success) {
attempt <- attempt + 1
if (verbose) base::message(base::paste("Retrying text", index, "- Attempt", attempt, "of", max_attempts))
}
}
if (!success && base::is.na(result)) {
result <- "An unknown error occurred."
if (verbose) base::message(base::paste("Failed to annotate text", index, "after", max_attempts, "attempts."))
}
return(result)
}
# Vectorize the function to process all entries in the column
annotations <- purrr::map2_chr(user_prompt, base::seq_along(user_prompt), ~annotate_text(.x, .y, base::length(user_prompt)))
# Write the results to a CSV file
if (storage) utils::write.csv(data.frame(sys_prompt=sys_prompt,user_prompt=user_prompt,aitag = annotations), filepath, row.names = FALSE)
# Return the vector of annotations
return(annotations)
}
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- c("Apple", "Tomato", "Broccoli")
annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?",storage = FALSE)
#' @examples
#' \dontrun{
#' my_data <- c("Apple", "Tomato", "Broccoli")
#' annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?")
#' }
#' @importFrom httr2 request req_headers req_body_json req_timeout req_perform resp_body_json
#' @importFrom stringr str_c str_replace_all
#' @importFrom dplyr if_else
#' @importFrom utils write.csv
#' @export
tag_gpt <- function(user_prompt,
sys_prompt = "",
temperature = 0,
api_key = base::Sys.getenv("openai_key"),
api_url = base::Sys.getenv("openai_url"),
model = "gpt-3.5-turbo-0125",
verbose = TRUE,
storage = TRUE) {
# Ensure the API URL is complete
api_url <- stringr::str_c(api_url, "/v1/chat/completions")
# Add filepath for output
columnname <- base::deparse(base::substitute(user_prompt))
# Function to process each text entry
annotate_text <- function(text, index, total) {
to_annotate_text <- stringr::str_replace_all(text, "(\n|\r)", " ")
authorization <- dplyr::if_else(api_url == "https://api.openai.com/v1/chat/completions", api_key, base::paste0("Bearer ", api_key))
attempt <- 1
max_attempts <- 3
success <- FALSE
result <- NA_character_
while (!success && attempt <= max_attempts) {
base::Sys.sleep(0.6) # Sleep to avoid rate limiting
tryCatch({
response <- httr2::request(api_url) |>
httr2::req_headers(`Content-Type` = "application/json", `Authorization` = authorization) |>
httr2::req_body_json(list(
model = model,
temperature = temperature,
messages = list(
list(role = "system", content = sys_prompt),
list(role = "user", content = to_annotate_text)
)
)) |>
httr2::req_timeout(60000) |> # 60 seconds timeout
httr2::req_perform()
if (response$status_code < 400) {
response_content <- httr2::resp_body_json(response)
result <- response_content$choices[[1]]$message$content
success <- TRUE
if (verbose) base::message("status_id: ", index, " of ", total, "\n", "sys_prompt: ", sys_prompt, "\n", "user_prompt: ", to_annotate_text)
if (verbose) base::message("ChatGPT: ", result, "\n")
} else {
# Capture and return the error message from the response
error_content <- httr2::resp_body_json(response)
result <- error_content$error$message
if (verbose) base::message(base::paste("Error annotating text", index, ":", result))
break
}
}, error = function(e) {
if (verbose) base::message(base::paste("Error on text", index, ":", e$message))
})
if (!success) {
attempt <- attempt + 1
if (verbose) base::message(base::paste("Retrying text", index, "- Attempt", attempt, "of", max_attempts))
}
}
if (!success && base::is.na(result)) {
result <- "An unknown error occurred."
if (verbose) base::message(base::paste("Failed to annotate text", index, "after", max_attempts, "attempts."))
}
return(result)
}
# Vectorize the function to process all entries in the column
annotations <- purrr::map2_chr(user_prompt, base::seq_along(user_prompt), ~annotate_text(.x, .y, base::length(user_prompt)))
# Write the results to a CSV file
if (storage) filepath0 <- stringr::str_c("llm_output/", columnname, "/")
if (storage) if (!base::dir.exists(filepath0)) {
base::dir.create(filepath0, recursive = TRUE)
}
if (storage) filepath <- stringr::str_c(filepath0, model, ".csv")
if (storage) base::print(base::paste("Writing CSV file to:", filepath))
if (storage) utils::write.csv(data.frame(sys_prompt=sys_prompt,user_prompt=user_prompt,aitag = annotations), filepath, row.names = FALSE)
# Return the vector of annotations
return(annotations)
}
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- c("Apple", "Tomato", "Broccoli")
annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?",storage = FALSE)
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- c("Apple", "Tomato", "Broccoli")
annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?",storage = TRUE)
#' @examples
#' \dontrun{
#' my_data <- c("Apple", "Tomato", "Broccoli")
#' annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?")
#' }
#' @importFrom httr2 request req_headers req_body_json req_timeout req_perform resp_body_json
#' @importFrom stringr str_c str_replace_all
#' @importFrom dplyr if_else
#' @importFrom utils write.csv
#' @export
tag_gpt <- function(user_prompt,
sys_prompt = "",
temperature = 0,
api_key = base::Sys.getenv("openai_key"),
api_url = base::Sys.getenv("openai_url"),
model = "gpt-3.5-turbo-0125",
verbose = TRUE,
storage = TRUE,
rate_limit = 0.6) {
# Ensure the API URL is complete
api_url <- stringr::str_c(api_url, "/v1/chat/completions")
# Add filepath for output
columnname <- base::deparse(base::substitute(user_prompt))
# Function to process each text entry
annotate_text <- function(text, index, total) {
to_annotate_text <- stringr::str_replace_all(text, "(\n|\r)", " ")
authorization <- dplyr::if_else(api_url == "https://api.openai.com/v1/chat/completions", api_key, base::paste0("Bearer ", api_key))
attempt <- 1
max_attempts <- 3
success <- FALSE
result <- NA_character_
while (!success && attempt <= max_attempts) {
base::Sys.sleep(rate_limit) # Sleep to avoid rate limiting
tryCatch({
response <- httr2::request(api_url) |>
httr2::req_headers(`Content-Type` = "application/json", `Authorization` = authorization) |>
httr2::req_body_json(list(
model = model,
temperature = temperature,
messages = list(
list(role = "system", content = sys_prompt),
list(role = "user", content = to_annotate_text)
)
)) |>
httr2::req_timeout(60000) |> # 60 seconds timeout
httr2::req_perform()
if (response$status_code < 400) {
response_content <- httr2::resp_body_json(response)
result <- response_content$choices[[1]]$message$content
success <- TRUE
if (verbose) base::message("status_id: ", index, " of ", total, "\n", "sys_prompt: ", sys_prompt, "\n", "user_prompt: ", to_annotate_text)
if (verbose) base::message("ChatGPT: ", result, "\n")
} else {
# Capture and return the error message from the response
error_content <- httr2::resp_body_json(response)
result <- error_content$error$message
if (verbose) base::message(base::paste("Error annotating text", index, ":", result))
break
}
}, error = function(e) {
if (verbose) base::message(base::paste("Error on text", index, ":", e$message))
})
if (!success) {
attempt <- attempt + 1
if (verbose) base::message(base::paste("Retrying text", index, "- Attempt", attempt, "of", max_attempts))
}
}
if (!success && base::is.na(result)) {
result <- "An unknown error occurred."
if (verbose) base::message(base::paste("Failed to annotate text", index, "after", max_attempts, "attempts."))
}
return(result)
}
# Vectorize the function to process all entries in the column
annotations <- purrr::map2_chr(user_prompt, base::seq_along(user_prompt), ~annotate_text(.x, .y, base::length(user_prompt)))
# Write the results to a CSV file
if (storage) filepath0 <- stringr::str_c("llm_output/", columnname, "/")
if (storage) if (!base::dir.exists(filepath0)) {
base::dir.create(filepath0, recursive = TRUE)
}
if (storage) filepath <- stringr::str_c(filepath0, model, ".csv")
if (storage) base::print(base::paste("Writing CSV file to:", filepath))
if (storage) utils::write.csv(data.frame(sys_prompt=sys_prompt,user_prompt=user_prompt,aitag = annotations), filepath, row.names = FALSE)
# Return the vector of annotations
return(annotations)
}
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- c("Apple", "Tomato", "Broccoli")
annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?")
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- c("Apple", "Tomato", "Broccoli")
annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?",rate_limit = 0.8)
annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?",rate_limit = 0.8)
devtools::check()
devtools::check()
#' @examples
#' \dontrun{
#' my_data <- c("Apple", "Tomato", "Broccoli")
#' annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?")
#' }
#' @importFrom httr2 request req_headers req_body_json req_timeout req_perform resp_body_json
#' @importFrom stringr str_c str_replace_all
#' @importFrom dplyr if_else
#' @importFrom utils write.csv
#' @export
tag_gpt <- function(user_prompt,
sys_prompt = "",
temperature = 0,
api_key = base::Sys.getenv("openai_key"),
api_url = base::Sys.getenv("openai_url"),
model = "gpt-3.5-turbo-0125",
verbose = TRUE,
storage = TRUE,
rate_limit = 0.6) {
# Ensure the API URL is complete
api_url <- stringr::str_c(api_url, "/v1/chat/completions")
# Function to process each text entry
annotate_text <- function(text, index, total) {
to_annotate_text <- stringr::str_replace_all(text, "(\n|\r)", " ")
authorization <- dplyr::if_else(api_url == "https://api.openai.com/v1/chat/completions", api_key, base::paste0("Bearer ", api_key))
attempt <- 1
max_attempts <- 3
success <- FALSE
result <- NA_character_
while (!success && attempt <= max_attempts) {
base::Sys.sleep(rate_limit) # Sleep to avoid rate limiting
tryCatch({
response <- httr2::request(api_url) |>
httr2::req_headers(`Content-Type` = "application/json", `Authorization` = authorization) |>
httr2::req_body_json(list(
model = model,
temperature = temperature,
messages = list(
list(role = "system", content = sys_prompt),
list(role = "user", content = to_annotate_text)
)
)) |>
httr2::req_timeout(60000) |> # 60 seconds timeout
httr2::req_perform()
if (response$status_code < 400) {
response_content <- httr2::resp_body_json(response)
result <- response_content$choices[[1]]$message$content
success <- TRUE
if (verbose) base::message("status_id: ", index, " of ", total, "\n", "sys_prompt: ", sys_prompt, "\n", "user_prompt: ", to_annotate_text)
if (verbose) base::message("ChatGPT: ", result, "\n")
} else {
# Capture and return the error message from the response
error_content <- httr2::resp_body_json(response)
result <- error_content$error$message
if (verbose) base::message(base::paste("Error annotating text", index, ":", result))
break
}
}, error = function(e) {
if (verbose) base::message(base::paste("Error on text", index, ":", e$message))
})
if (!success) {
attempt <- attempt + 1
if (verbose) base::message(base::paste("Retrying text", index, "- Attempt", attempt, "of", max_attempts))
}
}
if (!success && base::is.na(result)) {
result <- "An unknown error occurred."
if (verbose) base::message(base::paste("Failed to annotate text", index, "after", max_attempts, "attempts."))
}
return(result)
}
# Vectorize the function to process all entries in the column
annotations <- purrr::map2_chr(user_prompt,
base::seq_along(user_prompt),
~annotate_text(.x, .y, base::length(user_prompt)))
if (storage) {
current_time <- Sys.time()
formatted_time <- format(current_time, "%Y-%m-%d_%H-%M-%S")
columnname <- base::deparse(base::substitute(user_prompt))
create_filepath <- function(columnname, model, formatted_time) {
# Create the directory if it does not exist
filepath0 <- stringr::str_c("llm_output/", columnname, "/")
if (!base::dir.exists(filepath0)) {
base::dir.create(filepath0, recursive = TRUE)
}
filepath <- stringr::str_c(filepath0, model, "_", formatted_time, ".csv")
return(filepath)
}
write_csv <- function(sys_prompt, user_prompt, annotations, current_time, filepath) {
# Print the filepath
base::print(base::paste("Writing CSV file to:", filepath))
# Write the CSV file
utils::write.csv(data.frame(
sys_prompt = sys_prompt,
user_prompt = user_prompt,
response = annotations,
time = current_time
),
filepath,
row.names = FALSE)
}
filepath <- create_filepath(columnname, model, formatted_time)
write_csv(sys_prompt, user_prompt, annotations, current_time, filepath)
}
# Return the vector of annotations
return(annotations)
}
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- c("Apple", "Tomato", "Broccoli")
annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?")
#' The function also saves the annotated responses as a CSV file in the "LLMoutput/columnname/model.csv" path.
#' @examples
#' \dontrun{
#' my_data <- c("Apple", "Tomato", "Broccoli")
#' annotated_data <- tag_perplexity(my_data, sys_prompt = "Which one is a fruit?")
#' }
#' @importFrom httr2 request req_headers req_body_json req_timeout req_perform resp_body_json
#' @importFrom stringr str_c
#' @importFrom utils write.csv
#' @export
tag_perplexity <- function(user_prompt,
sys_prompt = "Be precise and concise.",
api_key = base::Sys.getenv("perplexity_key"),
model = "mistral-7b-instruct",
api_url = "https://api.perplexity.ai/chat/completions",
verbose = TRUE,
storage = TRUE,
rate_limit = 1) {
api_key <- base::as.character(api_key)
# Function to process each text entry
annotate_text <- function(text, index, total) {
to_annotate_text <- base::gsub("(\n|\r)", " ", text)
authorization <- base::paste0("Bearer ", api_key)
attempt <- 1
max_attempts <- 3
success <- FALSE
result <- NA_character_
while (!success && attempt <= max_attempts) {
base::Sys.sleep(rate_limit) # Sleep to avoid rate limiting
tryCatch({
response <- httr2::request(api_url) |>
httr2::req_headers(`Content-Type` = "application/json", `Authorization` = authorization) |>
httr2::req_body_json(list(
model = model,
messages = list(
list(role = "system", content = sys_prompt),
list(role = "user", content = to_annotate_text)
)
)) |>
httr2::req_timeout(60000) |>
httr2::req_perform()
if (response$status_code < 400) {
response_content <- httr2::resp_body_json(response)
result <- response_content$choices[[1]]$message$content
success <- TRUE
if (verbose) {
base::message("status_id: ", index, " of ", total, "\n", "sys_prompt: ", sys_prompt, "\n", "user_prompt: ", to_annotate_text)
base::message("Perplexity: ", result, "\n")
}
} else {
# Capture and return the error message from the response
error_content <- httr2::resp_body_json(response)
result <- error_content$error$message
if (verbose) base::message(base::paste("Error annotating text", index, ":", result))
break
}
}, error = function(e) {
if (verbose) base::message(base::paste("Error on text", index, ":", e$message))
})
if (!success) {
attempt <- attempt + 1
if (verbose) base::message(base::paste("Retrying text", index, "- Attempt", attempt, "of", max_attempts))
}
}
if (!success && base::is.na(result)) {
result <- "An unknown error occurred."
if (verbose) base::message(base::paste("Failed to annotate text", index, "after", max_attempts, "attempts."))
}
return(result)
}
# Vectorize the function to process all entries in the column
annotations <- purrr::map2_chr(user_prompt, base::seq_along(user_prompt), ~annotate_text(.x, .y, base::length(user_prompt)))
if (storage) {
current_time <- Sys.time()
formatted_time <- format(current_time, "%Y-%m-%d_%H-%M-%S")
columnname <- base::deparse(base::substitute(user_prompt))
create_filepath <- function(columnname, model, formatted_time) {
# Create the directory if it does not exist
filepath0 <- stringr::str_c("llm_output/", columnname, "/")
if (!base::dir.exists(filepath0)) {
base::dir.create(filepath0, recursive = TRUE)
}
filepath <- stringr::str_c(filepath0, model, "_", formatted_time, ".csv")
return(filepath)
}
write_csv <- function(sys_prompt, user_prompt, annotations, current_time, filepath) {
# Print the filepath
base::print(base::paste("Writing CSV file to:", filepath))
# Write the CSV file
utils::write.csv(data.frame(
sys_prompt = sys_prompt,
user_prompt = user_prompt,
response = annotations,
time = current_time
),
filepath,
row.names = FALSE)
}
filepath <- create_filepath(columnname, model, formatted_time)
write_csv(sys_prompt, user_prompt, annotations, current_time, filepath)
}
# Return the vector of annotations
return(annotations)
}
Sys.setenv(perplexity_key="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")
my_data <- c("Apple", "Tomato", "Broccoli")
annotated_data <- tag_perplexity(my_data, sys_prompt = "Which one is a fruit?")
devtools::check()
wowsobig_check
devtools::check()
