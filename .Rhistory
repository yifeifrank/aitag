annotations <- map2_chr(user_prompt, seq_along(user_prompt), ~annotate_text(.x, .y, length(user_prompt)))
# Write the annotations to a CSV file
utils::write.csv(annotations, filepath, row.names = FALSE)
# Return the vector of annotations
return(annotations)
}
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- data.frame(
id = c("1", "2", "3"),
text = c("Example text 1", "Example text 2", "Example text 3")
)
annotated_data <- my_data |> mutate(result_col = tag_gpt(text, sys_prompt = "Classify the sentiment of this text as positive, negative or neutral."))
annotated_data$result_col <- tag_gpt(my_data$text, sys_prompt = "Classify the sentiment of this text as positive, negative or neutral.")
#' @examples
#' \dontrun{
#' my_data <- c("Example text 1", "Example text 2", "Example text 3")
#' annotated_data <- tag_gpt(my_data, sys_prompt = "Classify the sentiment of this text as positive, negative or neutral.")
#' }
#' @importFrom httr2 request req_headers req_body_json req_timeout req_perform resp_body_json
#' @importFrom stringr str_c str_replace_all
#' @importFrom dplyr if_else
#' @importFrom utils write.csv
#' @export
tag_gpt <- function(user_prompt,
sys_prompt = "",
temperature = 0,
api_key = base::Sys.getenv("openai_key"),
api_url = base::Sys.getenv("openai_url"),
model = "gpt-3.5-turbo-0125",
verbose = TRUE) {
# Ensure the API URL is complete
api_url <- stringr::str_c(api_url, "/v1/chat/completions")
# Add filepath for output
columnname <- base::deparse(base::substitute(user_prompt))
filepath0 <- stringr::str_c("LLMoutput/", columnname, "/")
if (!base::dir.exists(filepath0)) {
base::dir.create(filepath0, recursive = TRUE)
}
filepath <- stringr::str_c(filepath0, model, ".csv")
base::print(base::paste("Writing CSV file to:", filepath))
# Function to process each text entry
annotate_text <- function(text, index, total) {
to_annotate_text <- stringr::str_replace_all(text, "(\n|\r)", " ")
authorization <- dplyr::if_else(api_url == "https://api.openai.com/v1/chat/completions", api_key, base::paste0("Bearer ", api_key))
attempt <- 1
max_attempts <- 3
success <- FALSE
result <- base::NA_character_
#' @examples
#' \dontrun{
#' my_data <- c("Example text 1", "Example text 2", "Example text 3")
#' annotated_data <- tag_gpt(my_data, sys_prompt = "Classify the sentiment of this text as positive, negative or neutral.")
#' }
#' @importFrom httr2 request req_headers req_body_json req_timeout req_perform resp_body_json
#' @importFrom stringr str_c str_replace_all
#' @importFrom dplyr if_else
#' @importFrom utils write.csv
#' @export
tag_gpt <- function(user_prompt,
sys_prompt = "",
temperature = 0,
api_key = base::Sys.getenv("openai_key"),
api_url = base::Sys.getenv("openai_url"),
model = "gpt-3.5-turbo-0125",
verbose = TRUE) {
# Ensure the API URL is complete
api_url <- stringr::str_c(api_url, "/v1/chat/completions")
# Add filepath for output
columnname <- base::deparse(base::substitute(user_prompt))
filepath0 <- stringr::str_c("LLMoutput/", columnname, "/")
if (!base::dir.exists(filepath0)) {
base::dir.create(filepath0, recursive = TRUE)
}
filepath <- stringr::str_c(filepath0, model, ".csv")
base::print(base::paste("Writing CSV file to:", filepath))
# Function to process each text entry
annotate_text <- function(text, index, total) {
to_annotate_text <- stringr::str_replace_all(text, "(\n|\r)", " ")
authorization <- dplyr::if_else(api_url == "https://api.openai.com/v1/chat/completions", api_key, base::paste0("Bearer ", api_key))
attempt <- 1
max_attempts <- 3
success <- FALSE
result <- NA_character_
while (!success && attempt <= max_attempts) {
base::Sys.sleep(0.6) # Sleep to avoid rate limiting
tryCatch({
response <- httr2::request(api_url) |>
httr2::req_headers(`Content-Type` = "application/json", `Authorization` = authorization) |>
httr2::req_body_json(list(
model = model,
temperature = temperature,
messages = list(
list(role = "system", content = sys_prompt),
list(role = "user", content = to_annotate_text)
)
)) |>
httr2::req_timeout(60000) |> # 60 seconds timeout
httr2::req_perform()
if (response$status_code < 400) {
response_content <- httr2::resp_body_json(response)
result <- response_content$choices[[1]]$message$content
success <- TRUE
if (verbose) base::message("status_id: ", index, " of ", total, "\n", "sys_prompt: ", sys_prompt, "\n", "user_prompt: ", to_annotate_text)
if (verbose) base::message("ChatGPT: ", result, "\n")
} else {
# Capture and return the error message from the response
error_content <- httr2::resp_body_json(response)
result <- error_content$error$message
if (verbose) base::message(base::paste("Error annotating text", index, ":", result))
break
}
}, error = function(e) {
if (verbose) base::message(base::paste("Error on text", index, ":", e$message))
})
if (!success) {
attempt <- attempt + 1
if (verbose) base::message(base::paste("Retrying text", index, "- Attempt", attempt, "of", max_attempts))
}
}
if (!success && base::is.na(result)) {
result <- "An unknown error occurred."
if (verbose) base::message(base::paste("Failed to annotate text", index, "after", max_attempts, "attempts."))
}
return(result)
}
# Vectorize the function to process all entries in the column
annotations <- purrr::map2_chr(user_prompt, base::seq_along(user_prompt), ~annotate_text(.x, .y, base::length(user_prompt)))
# Write the results to a CSV file
utils::write.csv(data.frame(aitag = annotations), filepath, row.names = FALSE)
# Return the vector of annotations
return(annotations)
}
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- data.frame(
id = c("1", "2", "3"),
text = c("Example text 1", "Example text 2", "Example text 3")
)
annotated_data <- my_data |> mutate(result_col = tag_gpt(text, sys_prompt = "Classify the sentiment of this text as positive, negative or neutral."))
@export
#' @examples
#' \dontrun{
#' my_data <- c("Example text 1", "Example text 2", "Example text 3")
#' annotated_data <- tag_gpt(my_data, sys_prompt = "Classify the sentiment of this text as positive, negative or neutral.")
#' }
#' @importFrom httr2 request req_headers req_body_json req_timeout req_perform resp_body_json
#' @importFrom stringr str_c str_replace_all
#' @importFrom dplyr if_else
#' @importFrom utils write.csv
#' @export
tag_gpt <- function(user_prompt,
sys_prompt = "",
temperature = 0,
api_key = base::Sys.getenv("openai_key"),
api_url = base::Sys.getenv("openai_url"),
model = "gpt-3.5-turbo-0125",
verbose = TRUE) {
# Ensure the API URL is complete
api_url <- stringr::str_c(api_url, "/v1/chat/completions")
# Add filepath for output
columnname <- base::deparse(base::substitute(user_prompt))
filepath0 <- stringr::str_c("LLMoutput/", columnname, "/")
if (!base::dir.exists(filepath0)) {
base::dir.create(filepath0, recursive = TRUE)
}
filepath <- stringr::str_c(filepath0, model, ".csv")
base::print(base::paste("Writing CSV file to:", filepath))
# Function to process each text entry
annotate_text <- function(text, index, total) {
to_annotate_text <- stringr::str_replace_all(text, "(\n|\r)", " ")
authorization <- dplyr::if_else(api_url == "https://api.openai.com/v1/chat/completions", api_key, base::paste0("Bearer ", api_key))
attempt <- 1
max_attempts <- 3
success <- FALSE
result <- NA_character_
while (!success && attempt <= max_attempts) {
base::Sys.sleep(0.6) # Sleep to avoid rate limiting
tryCatch({
response <- httr2::request(api_url) |>
httr2::req_headers(`Content-Type` = "application/json", `Authorization` = authorization) |>
httr2::req_body_json(list(
model = model,
temperature = temperature,
messages = list(
list(role = "system", content = sys_prompt),
list(role = "user", content = to_annotate_text)
)
)) |>
httr2::req_timeout(60000) |> # 60 seconds timeout
httr2::req_perform()
if (response$status_code < 400) {
response_content <- httr2::resp_body_json(response)
result <- response_content$choices[[1]]$message$content
success <- TRUE
if (verbose) base::message("status_id: ", index, " of ", total, "\n", "sys_prompt: ", sys_prompt, "\n", "user_prompt: ", to_annotate_text)
if (verbose) base::message("ChatGPT: ", result, "\n")
} else {
# Capture and return the error message from the response
error_content <- httr2::resp_body_json(response)
result <- error_content$error$message
if (verbose) base::message(base::paste("Error annotating text", index, ":", result))
break
}
}, error = function(e) {
if (verbose) base::message(base::paste("Error on text", index, ":", e$message))
})
if (!success) {
attempt <- attempt + 1
if (verbose) base::message(base::paste("Retrying text", index, "- Attempt", attempt, "of", max_attempts))
}
}
if (!success && base::is.na(result)) {
result <- "An unknown error occurred."
if (verbose) base::message(base::paste("Failed to annotate text", index, "after", max_attempts, "attempts."))
}
return(result)
}
# Vectorize the function to process all entries in the column
annotations <- purrr::map2_chr(user_prompt, base::seq_along(user_prompt), ~annotate_text(.x, .y, base::length(user_prompt)))
# Write the results to a CSV file
utils::write.csv(data.frame(aitag = annotations), filepath, row.names = FALSE)
# Return the vector of annotations
return(annotations)
}
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- data.frame(
id = c("1", "2", "3"),
text = c("Example text 1", "Example text 2", "Example text 3")
)
annotated_data <- my_data |> mutate(result_col = tag_gpt(text, sys_prompt = "Classify the sentiment of this text as positive, negative or neutral."))
annotated_data <- my_data |> mutate(result_col = tag_perplexity(text, sys_prompt = "Classify the sentiment of this text as positive, negative or neutral."))
#' The function also saves the annotated responses as a CSV file in the "LLMoutput/columnname/model.csv" path.
#' @examples
#' \dontrun{
#' my_data <- c("Example text 1", "Example text 2", "Example text 3")
#' annotated_data <- tag_perplexity(my_data, "Be precise and concise.")
#' }
#' @importFrom httr2 request req_headers req_body_json req_timeout req_perform resp_body_json
#' @importFrom stringr str_c str_replace_all
#' @importFrom utils write.csv
#' @export
tag_perplexity <- function(column,
instruction = "Be precise and concise.",
api_key = base::Sys.getenv("perplexity_key"),
model = "mistral-7b-instruct",
api_url = "https://api.perplexity.ai/chat/completions") {
# Ensure the API URL is complete
api_url <- stringr::str_c(api_url, "/v1/chat/completions")
# Add filepath for output
columnname <- base::deparse(base::substitute(column))
filepath0 <- stringr::str_c("LLMoutput/", columnname, "/")
if (!base::dir.exists(filepath0)) {
base::dir.create(filepath0, recursive = TRUE)
}
filepath <- stringr::str_c(filepath0, model, ".csv")
base::print(base::paste("Writing CSV file to:", filepath))
# Function to process each text entry
annotate_text <- function(text, index, total) {
to_annotate_text <- stringr::str_replace_all(text, "(\n|\r)", " ")
authorization <- base::paste0("Bearer ", api_key)
attempt <- 1
max_attempts <- 3
success <- FALSE
result <- base::NA_character_
#' The function also saves the annotated responses as a CSV file in the "LLMoutput/columnname/model.csv" path.
#' @examples
#' \dontrun{
#' my_data <- c("Example text 1", "Example text 2", "Example text 3")
#' annotated_data <- tag_perplexity(my_data, "Be precise and concise.")
#' }
#' @importFrom httr2 request req_headers req_body_json req_timeout req_perform resp_body_json
#' @importFrom stringr str_c str_replace_all
#' @importFrom utils write.csv
#' @export
tag_perplexity <- function(column,
instruction = "Be precise and concise.",
api_key = base::Sys.getenv("perplexity_key"),
model = "mistral-7b-instruct",
api_url = "https://api.perplexity.ai/chat/completions") {
# Ensure the API URL is complete
api_url <- stringr::str_c(api_url, "/v1/chat/completions")
# Add filepath for output
columnname <- base::deparse(base::substitute(column))
filepath0 <- stringr::str_c("LLMoutput/", columnname, "/")
if (!base::dir.exists(filepath0)) {
base::dir.create(filepath0, recursive = TRUE)
}
filepath <- stringr::str_c(filepath0, model, ".csv")
base::print(base::paste("Writing CSV file to:", filepath))
# Function to process each text entry
annotate_text <- function(text, index, total) {
to_annotate_text <- stringr::str_replace_all(text, "(\n|\r)", " ")
authorization <- base::paste0("Bearer ", api_key)
attempt <- 1
max_attempts <- 3
success <- FALSE
result <- NA_character_
while (!success && attempt <= max_attempts) {
base::Sys.sleep(0.6) # Sleep to avoid rate limiting
tryCatch({
response <- httr2::request(api_url) |>
httr2::req_headers(`Content-Type` = "application/json", `Authorization` = authorization) |>
httr2::req_body_json(list(
model = model,
messages = list(
list(role = "system", content = instruction),
list(role = "user", content = to_annotate_text)
)
)) |>
httr2::req_timeout(60000) |> # 60 seconds timeout
httr2::req_perform()
if (response$status_code < 400) {
response_content <- httr2::resp_body_json(response)
result <- response_content$choices[[1]]$message$content
success <- TRUE
base::message("status_id: ", index, " of ", total, "\n", "instruction: ", instruction, "\n", "text: ", to_annotate_text)
base::message("Perplexity: ", result, "\n")
} else {
# Capture and return the error message from the response
error_content <- httr2::resp_body_json(response)
result <- error_content$error$message
base::message(base::paste("Error annotating text", index, ":", result))
break
}
}, error = function(e) {
base::message(base::paste("Error on text", index, ":", e$message))
})
if (!success) {
attempt <- attempt + 1
base::message(base::paste("Retrying text", index, "- Attempt", attempt, "of", max_attempts))
}
}
if (!success && base::is.na(result)) {
result <- "An unknown error occurred."
base::message(base::paste("Failed to annotate text", index, "after", max_attempts, "attempts."))
}
return(result)
}
# Vectorize the function to process all entries in the column
annotations <- purrr::map2_chr(column, base::seq_along(column), ~annotate_text(.x, .y, base::length(column)))
# Write the results to a CSV file
utils::write.csv(data.frame(id = base::seq_along(column), response = annotations), filepath, row.names = FALSE)
# Return the vector of annotations
return(annotations)
}
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- data.frame(
id = c("1", "2", "3"),
text = c("Example text 1", "Example text 2", "Example text 3")
)
annotated_data <- my_data |> mutate(result_col = tag_perplexity(text, sys_prompt = "Classify the sentiment of this text as positive, negative or neutral."))
#' The function also saves the annotated responses as a CSV file in the "LLMoutput/columnname/model.csv" path.
#' @examples
#' \dontrun{
#' my_data <- c("Example text 1", "Example text 2", "Example text 3")
#' annotated_data <- tag_perplexity(my_data, sys_prompt = "Be precise and concise.")
#' }
#' @importFrom httr2 request req_headers req_body_json req_timeout req_perform resp_body_json
#' @importFrom stringr str_c
#' @importFrom utils write.csv
#' @export
tag_perplexity <- function(user_prompt,
sys_prompt = "Be precise and concise.",
api_key = base::Sys.getenv("perplexity_key"),
model = "mistral-7b-instruct",
api_url = "https://api.perplexity.ai/chat/completions",
verbose = TRUE) {
columnname <- base::deparse(base::substitute(user_prompt))
api_key <- base::as.character(api_key)
filepath0 <- stringr::str_c("LLMoutput/", columnname, "/")
if (!base::dir.exists(filepath0)) {
base::dir.create(filepath0, recursive = TRUE)
}
filepath <- stringr::str_c(filepath0, model, ".csv")
if (verbose) base::print(base::paste("Writing CSV file to:", filepath))
# Function to process each text entry
annotate_text <- function(text, index, total) {
to_annotate_text <- base::gsub("(\n|\r)", " ", text)
authorization <- base::paste0("Bearer ", api_key)
attempt <- 1
max_attempts <- 3
success <- FALSE
result <- base::NA_character_
#' The function also saves the annotated responses as a CSV file in the "LLMoutput/columnname/model.csv" path.
#' @examples
#' \dontrun{
#' my_data <- c("Example text 1", "Example text 2", "Example text 3")
#' annotated_data <- tag_perplexity(my_data, sys_prompt = "Be precise and concise.")
#' }
#' @importFrom httr2 request req_headers req_body_json req_timeout req_perform resp_body_json
#' @importFrom stringr str_c
#' @importFrom utils write.csv
#' @export
tag_perplexity <- function(user_prompt,
sys_prompt = "Be precise and concise.",
api_key = base::Sys.getenv("perplexity_key"),
model = "mistral-7b-instruct",
api_url = "https://api.perplexity.ai/chat/completions",
verbose = TRUE) {
columnname <- base::deparse(base::substitute(user_prompt))
api_key <- base::as.character(api_key)
filepath0 <- stringr::str_c("LLMoutput/", columnname, "/")
if (!base::dir.exists(filepath0)) {
base::dir.create(filepath0, recursive = TRUE)
}
filepath <- stringr::str_c(filepath0, model, ".csv")
if (verbose) base::print(base::paste("Writing CSV file to:", filepath))
# Function to process each text entry
annotate_text <- function(text, index, total) {
to_annotate_text <- base::gsub("(\n|\r)", " ", text)
authorization <- base::paste0("Bearer ", api_key)
attempt <- 1
max_attempts <- 3
success <- FALSE
result <- NA_character_
while (!success && attempt <= max_attempts) {
base::Sys.sleep(0.6) # Sleep to avoid rate limiting
tryCatch({
response <- httr2::request(api_url) |>
httr2::req_headers(`Content-Type` = "application/json", `Authorization` = authorization) |>
httr2::req_body_json(list(
model = model,
messages = list(
list(role = "system", content = sys_prompt),
list(role = "user", content = to_annotate_text)
)
)) |>
httr2::req_timeout(60000) |>
httr2::req_perform()
if (response$status_code < 400) {
response_content <- httr2::resp_body_json(response)
result <- response_content$choices[[1]]$message$content
success <- TRUE
if (verbose) base::message("status_id: ", index, " of ", total, "\n", "sys_prompt: ", sys_prompt, "\n", "user_prompt: ", to_annotate_text)
if (verbose) base::message("Perplexity: ", result, "\n")
} else {
# Capture and return the error message from the response
error_content <- httr2::resp_body_json(response)
result <- error_content$error$message
if (verbose) base::message(base::paste("Error annotating text", index, ":", result))
break
}
}, error = function(e) {
if (verbose) base::message(base::paste("Error on text", index, ":", e$message))
})
if (!success) {
attempt <- attempt + 1
if (verbose) base::message(base::paste("Retrying text", index, "- Attempt", attempt, "of", max_attempts))
}
}
if (!success && base::is.na(result)) {
result <- "An unknown error occurred."
if (verbose) base::message(base::paste("Failed to annotate text", index, "after", max_attempts, "attempts."))
}
return(result)
}
# Vectorize the function to process all entries in the column
annotations <- purrr::map2_chr(user_prompt, base::seq_along(user_prompt), ~annotate_text(.x, .y, base::length(user_prompt)))
# Write the results to a CSV file
utils::write.csv(base::data.frame(response = annotations), filepath, row.names = FALSE)
# Return the vector of annotations
return(annotations)
}
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- data.frame(
id = c("1", "2", "3"),
text = c("Example text 1", "Example text 2", "Example text 3")
)
annotated_data <- my_data |> mutate(result_col = tag_perplexity(text, sys_prompt = "Classify the sentiment of this text as positive, negative or neutral."))
Sys.setenv(perplexity_key="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")
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- data.frame(
id = c("1", "2", "3"),
text = c("Example text 1", "Example text 2", "Example text 3")
)
annotated_data <- my_data |> mutate(result_col = tag_perplexity(text, sys_prompt = "Classify the sentiment of this text as positive, negative or neutral."))
annotated_data <- my_data |> mutate(result_col = tag_perplexity(text, sys_prompt = "Classify the sentiment of this text as positive, negative or neutral.",model="llama-3.1-sonar-small-128k-online"))
my_data <- data.frame(
id = c("1", "2", "3"),
text = c("I am good", "I am bad", "I am neutral")
)
annotated_data <- my_data |> mutate(result_col = tag_perplexity(text, sys_prompt = "Classify the sentiment of this text as positive, negative or neutral.",model="llama-3.1-sonar-small-128k-online"))
my_data <- data.frame(
id = c("1", "2", "3"),
text = c("Yay!", "Nay!", "Whatever")
)
annotated_data <- my_data |> mutate(result_col = tag_perplexity(text, sys_prompt = "Classify the sentiment of this text as positive, negative or neutral.",model="llama-3.1-sonar-small-128k-online"))
my_data <- data.frame(
id = c("1", "2", "3"),
text = c("Yay!", "Nah.", "Whatever")
)
annotated_data <- my_data |> mutate(result_col = tag_perplexity(text, sys_prompt = "Classify the sentiment of this text as positive, negative or neutral.",model="llama-3.1-sonar-small-128k-online"))
my_data <- data.frame(
id = c("1", "2", "3"),
text = c("Yay!", "Off", "Whatever")
)
annotated_data <- my_data |> mutate(result_col = tag_perplexity(text, sys_prompt = "Classify the sentiment of this text as positive, negative or neutral.",model="llama-3.1-sonar-small-128k-online"))
devtools::check()
devtools::check()
devtools::check()
devtools::check()
git push origin master
git status
ls -a
devtools::check()
devtools::check()
ls ~/.ssh
