list(role = "user", content = to_annotate_text)
)
)) |>
httr2::req_timeout(60000) |> # 60 seconds timeout
httr2::req_perform()
if (response$status_code < 400) {
response_content <- httr2::resp_body_json(response)
result <- response_content$choices[[1]]$message$content
success <- TRUE
if (verbose) base::message("status_id: ", index, " of ", total, "\n", "sys_prompt: ", sys_prompt, "\n", "user_prompt: ", to_annotate_text)
if (verbose) base::message("ChatGPT: ", result, "\n")
} else {
# Capture and return the error message from the response
error_content <- httr2::resp_body_json(response)
result <- error_content$error$message
if (verbose) base::message(base::paste("Error annotating text", index, ":", result))
break
}
}, error = function(e) {
if (verbose) base::message(base::paste("Error on text", index, ":", e$message))
})
if (!success) {
attempt <- attempt + 1
if (verbose) base::message(base::paste("Retrying text", index, "- Attempt", attempt, "of", max_attempts))
}
}
if (!success && base::is.na(result)) {
result <- "An unknown error occurred."
if (verbose) base::message(base::paste("Failed to annotate text", index, "after", max_attempts, "attempts."))
}
return(result)
}
# Vectorize the function to process all entries in the column
annotations <- purrr::map2_chr(user_prompt, base::seq_along(user_prompt), ~annotate_text(.x, .y, base::length(user_prompt)))
# Write the results to a CSV file
utils::write.csv(data.frame(aitag = annotations), filepath, row.names = FALSE)
# Return the vector of annotations
return(annotations)
}
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- c("Apple", "Tomato", "Broccoli")
annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?")
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- c("Apple", "Tomato", "Broccoli")
annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?")
#' @examples
#' \dontrun{
#' my_data <- c("Apple", "Tomato", "Broccoli")
#' annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?")
#' }
#' @importFrom httr2 request req_headers req_body_json req_timeout req_perform resp_body_json
#' @importFrom stringr str_c str_replace_all
#' @importFrom dplyr if_else
#' @importFrom utils write.csv
#' @export
tag_gpt <- function(user_prompt,
sys_prompt = "",
temperature = 0,
api_key = base::Sys.getenv("openai_key"),
api_url = base::Sys.getenv("openai_url"),
model = "gpt-3.5-turbo-0125",
verbose = TRUE) {
# Ensure the API URL is complete
api_url <- stringr::str_c(api_url, "/v1/chat/completions")
# Add filepath for output
columnname <- base::deparse(base::substitute(user_prompt))
filepath0 <- stringr::str_c("LLMoutput/", columnname, "/")
if (!base::dir.exists(filepath0)) {
base::dir.create(filepath0, recursive = TRUE)
}
filepath <- stringr::str_c(filepath0, model, ".csv")
base::print(base::paste("Writing CSV file to:", filepath))
# Function to process each text entry
annotate_text <- function(text, index, total) {
to_annotate_text <- stringr::str_replace_all(text, "(\n|\r)", " ")
authorization <- dplyr::if_else(api_url == "https://api.openai.com/v1/chat/completions", api_key, base::paste0("Bearer ", api_key))
attempt <- 1
max_attempts <- 3
success <- FALSE
result <- NA_character_
while (!success && attempt <= max_attempts) {
base::Sys.sleep(0.6) # Sleep to avoid rate limiting
tryCatch({
response <- httr2::request(api_url) |>
httr2::req_headers(`Content-Type` = "application/json", `Authorization` = authorization) |>
httr2::req_body_json(list(
model = model,
temperature = temperature,
messages = list(
list(role = "system", content = sys_prompt),
list(role = "user", content = to_annotate_text)
)
)) |>
httr2::req_timeout(60000) |> # 60 seconds timeout
httr2::req_perform()
if (response$status_code < 400) {
response_content <- httr2::resp_body_json(response)
result <- response_content$choices[[1]]$message$content
success <- TRUE
if (verbose) base::message("status_id: ", index, " of ", total, "\n", "sys_prompt: ", sys_prompt, "\n", "user_prompt: ", to_annotate_text)
if (verbose) base::message("ChatGPT: ", result, "\n")
} else {
# Capture and return the error message from the response
error_content <- httr2::resp_body_json(response)
result <- error_content$error$message
if (verbose) base::message(base::paste("Error annotating text", index, ":", result))
break
}
}, error = function(e) {
if (verbose) base::message(base::paste("Error on text", index, ":", e$message))
})
if (!success) {
attempt <- attempt + 1
if (verbose) base::message(base::paste("Retrying text", index, "- Attempt", attempt, "of", max_attempts))
}
}
if (!success && base::is.na(result)) {
result <- "An unknown error occurred."
if (verbose) base::message(base::paste("Failed to annotate text", index, "after", max_attempts, "attempts."))
}
return(result)
}
# Vectorize the function to process all entries in the column
annotations <- purrr::map2_chr(user_prompt, base::seq_along(user_prompt), ~annotate_text(.x, .y, base::length(user_prompt)))
# Write the results to a CSV file
utils::write.csv(data.frame(aitag = annotations,user_prompt=user_prompt), filepath, row.names = FALSE)
# Return the vector of annotations
return(annotations)
}
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- c("Apple", "Tomato", "Broccoli")
annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?")
library(readr)
gpt_3_5_turbo_0125 <- read_csv("LLMoutput/my_data/gpt-3.5-turbo-0125.csv")
View(gpt_3_5_turbo_0125)
#' @examples
#' \dontrun{
#' my_data <- c("Apple", "Tomato", "Broccoli")
#' annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?")
#' }
#' @importFrom httr2 request req_headers req_body_json req_timeout req_perform resp_body_json
#' @importFrom stringr str_c str_replace_all
#' @importFrom dplyr if_else
#' @importFrom utils write.csv
#' @export
tag_gpt <- function(user_prompt,
sys_prompt = "",
temperature = 0,
api_key = base::Sys.getenv("openai_key"),
api_url = base::Sys.getenv("openai_url"),
model = "gpt-3.5-turbo-0125",
verbose = TRUE) {
# Ensure the API URL is complete
api_url <- stringr::str_c(api_url, "/v1/chat/completions")
# Add filepath for output
columnname <- base::deparse(base::substitute(user_prompt))
filepath0 <- stringr::str_c("LLMoutput/", columnname, "/")
if (!base::dir.exists(filepath0)) {
base::dir.create(filepath0, recursive = TRUE)
}
filepath <- stringr::str_c(filepath0, model, ".csv")
base::print(base::paste("Writing CSV file to:", filepath))
# Function to process each text entry
annotate_text <- function(text, index, total) {
to_annotate_text <- stringr::str_replace_all(text, "(\n|\r)", " ")
authorization <- dplyr::if_else(api_url == "https://api.openai.com/v1/chat/completions", api_key, base::paste0("Bearer ", api_key))
attempt <- 1
max_attempts <- 3
success <- FALSE
result <- NA_character_
while (!success && attempt <= max_attempts) {
base::Sys.sleep(0.6) # Sleep to avoid rate limiting
tryCatch({
response <- httr2::request(api_url) |>
httr2::req_headers(`Content-Type` = "application/json", `Authorization` = authorization) |>
httr2::req_body_json(list(
model = model,
temperature = temperature,
messages = list(
list(role = "system", content = sys_prompt),
list(role = "user", content = to_annotate_text)
)
)) |>
httr2::req_timeout(60000) |> # 60 seconds timeout
httr2::req_perform()
if (response$status_code < 400) {
response_content <- httr2::resp_body_json(response)
result <- response_content$choices[[1]]$message$content
success <- TRUE
if (verbose) base::message("status_id: ", index, " of ", total, "\n", "sys_prompt: ", sys_prompt, "\n", "user_prompt: ", to_annotate_text)
if (verbose) base::message("ChatGPT: ", result, "\n")
} else {
# Capture and return the error message from the response
error_content <- httr2::resp_body_json(response)
result <- error_content$error$message
if (verbose) base::message(base::paste("Error annotating text", index, ":", result))
break
}
}, error = function(e) {
if (verbose) base::message(base::paste("Error on text", index, ":", e$message))
})
if (!success) {
attempt <- attempt + 1
if (verbose) base::message(base::paste("Retrying text", index, "- Attempt", attempt, "of", max_attempts))
}
}
if (!success && base::is.na(result)) {
result <- "An unknown error occurred."
if (verbose) base::message(base::paste("Failed to annotate text", index, "after", max_attempts, "attempts."))
}
return(result)
}
# Vectorize the function to process all entries in the column
annotations <- purrr::map2_chr(user_prompt, base::seq_along(user_prompt), ~annotate_text(.x, .y, base::length(user_prompt)))
# Write the results to a CSV file
utils::write.csv(data.frame(sys_prompt=sys_prompt,user_prompt=user_prompt,aitag = annotations), filepath, row.names = FALSE)
# Return the vector of annotations
return(annotations)
}
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- c("Apple", "Tomato", "Broccoli")
annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?")
?tag_pplx
?tag_gpt
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- c("Apple", "Tomato", "Broccoli")
my_data <- c("Apple", "Tomato", "Broccoli")
annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?",storage = FALSE)
#' @examples
#' \dontrun{
#' my_data <- c("Apple", "Tomato", "Broccoli")
#' annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?")
#' }
#' @importFrom httr2 request req_headers req_body_json req_timeout req_perform resp_body_json
#' @importFrom stringr str_c str_replace_all
#' @importFrom dplyr if_else
#' @importFrom utils write.csv
#' @export
tag_gpt <- function(user_prompt,
sys_prompt = "",
temperature = 0,
api_key = base::Sys.getenv("openai_key"),
api_url = base::Sys.getenv("openai_url"),
model = "gpt-3.5-turbo-0125",
verbose = TRUE,
storage = TRUE) {
# Ensure the API URL is complete
api_url <- stringr::str_c(api_url, "/v1/chat/completions")
# Add filepath for output
columnname <- base::deparse(base::substitute(user_prompt))
filepath0 <- stringr::str_c("llm_output/", columnname, "/")
if (!base::dir.exists(filepath0)) {
base::dir.create(filepath0, recursive = TRUE)
}
filepath <- stringr::str_c(filepath0, model, ".csv")
base::print(base::paste("Writing CSV file to:", filepath))
# Function to process each text entry
annotate_text <- function(text, index, total) {
to_annotate_text <- stringr::str_replace_all(text, "(\n|\r)", " ")
authorization <- dplyr::if_else(api_url == "https://api.openai.com/v1/chat/completions", api_key, base::paste0("Bearer ", api_key))
attempt <- 1
max_attempts <- 3
success <- FALSE
result <- NA_character_
while (!success && attempt <= max_attempts) {
base::Sys.sleep(0.6) # Sleep to avoid rate limiting
tryCatch({
response <- httr2::request(api_url) |>
httr2::req_headers(`Content-Type` = "application/json", `Authorization` = authorization) |>
httr2::req_body_json(list(
model = model,
temperature = temperature,
messages = list(
list(role = "system", content = sys_prompt),
list(role = "user", content = to_annotate_text)
)
)) |>
httr2::req_timeout(60000) |> # 60 seconds timeout
httr2::req_perform()
if (response$status_code < 400) {
response_content <- httr2::resp_body_json(response)
result <- response_content$choices[[1]]$message$content
success <- TRUE
if (verbose) base::message("status_id: ", index, " of ", total, "\n", "sys_prompt: ", sys_prompt, "\n", "user_prompt: ", to_annotate_text)
if (verbose) base::message("ChatGPT: ", result, "\n")
} else {
# Capture and return the error message from the response
error_content <- httr2::resp_body_json(response)
result <- error_content$error$message
if (verbose) base::message(base::paste("Error annotating text", index, ":", result))
break
}
}, error = function(e) {
if (verbose) base::message(base::paste("Error on text", index, ":", e$message))
})
if (!success) {
attempt <- attempt + 1
if (verbose) base::message(base::paste("Retrying text", index, "- Attempt", attempt, "of", max_attempts))
}
}
if (!success && base::is.na(result)) {
result <- "An unknown error occurred."
if (verbose) base::message(base::paste("Failed to annotate text", index, "after", max_attempts, "attempts."))
}
return(result)
}
# Vectorize the function to process all entries in the column
annotations <- purrr::map2_chr(user_prompt, base::seq_along(user_prompt), ~annotate_text(.x, .y, base::length(user_prompt)))
# Write the results to a CSV file
if (storage) utils::write.csv(data.frame(sys_prompt=sys_prompt,user_prompt=user_prompt,aitag = annotations), filepath, row.names = FALSE)
# Return the vector of annotations
return(annotations)
}
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- c("Apple", "Tomato", "Broccoli")
annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?",storage = FALSE)
#' @examples
#' \dontrun{
#' my_data <- c("Apple", "Tomato", "Broccoli")
#' annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?")
#' }
#' @importFrom httr2 request req_headers req_body_json req_timeout req_perform resp_body_json
#' @importFrom stringr str_c str_replace_all
#' @importFrom dplyr if_else
#' @importFrom utils write.csv
#' @export
tag_gpt <- function(user_prompt,
sys_prompt = "",
temperature = 0,
api_key = base::Sys.getenv("openai_key"),
api_url = base::Sys.getenv("openai_url"),
model = "gpt-3.5-turbo-0125",
verbose = TRUE,
storage = TRUE) {
# Ensure the API URL is complete
api_url <- stringr::str_c(api_url, "/v1/chat/completions")
# Add filepath for output
columnname <- base::deparse(base::substitute(user_prompt))
# Function to process each text entry
annotate_text <- function(text, index, total) {
to_annotate_text <- stringr::str_replace_all(text, "(\n|\r)", " ")
authorization <- dplyr::if_else(api_url == "https://api.openai.com/v1/chat/completions", api_key, base::paste0("Bearer ", api_key))
attempt <- 1
max_attempts <- 3
success <- FALSE
result <- NA_character_
while (!success && attempt <= max_attempts) {
base::Sys.sleep(0.6) # Sleep to avoid rate limiting
tryCatch({
response <- httr2::request(api_url) |>
httr2::req_headers(`Content-Type` = "application/json", `Authorization` = authorization) |>
httr2::req_body_json(list(
model = model,
temperature = temperature,
messages = list(
list(role = "system", content = sys_prompt),
list(role = "user", content = to_annotate_text)
)
)) |>
httr2::req_timeout(60000) |> # 60 seconds timeout
httr2::req_perform()
if (response$status_code < 400) {
response_content <- httr2::resp_body_json(response)
result <- response_content$choices[[1]]$message$content
success <- TRUE
if (verbose) base::message("status_id: ", index, " of ", total, "\n", "sys_prompt: ", sys_prompt, "\n", "user_prompt: ", to_annotate_text)
if (verbose) base::message("ChatGPT: ", result, "\n")
} else {
# Capture and return the error message from the response
error_content <- httr2::resp_body_json(response)
result <- error_content$error$message
if (verbose) base::message(base::paste("Error annotating text", index, ":", result))
break
}
}, error = function(e) {
if (verbose) base::message(base::paste("Error on text", index, ":", e$message))
})
if (!success) {
attempt <- attempt + 1
if (verbose) base::message(base::paste("Retrying text", index, "- Attempt", attempt, "of", max_attempts))
}
}
if (!success && base::is.na(result)) {
result <- "An unknown error occurred."
if (verbose) base::message(base::paste("Failed to annotate text", index, "after", max_attempts, "attempts."))
}
return(result)
}
# Vectorize the function to process all entries in the column
annotations <- purrr::map2_chr(user_prompt, base::seq_along(user_prompt), ~annotate_text(.x, .y, base::length(user_prompt)))
# Write the results to a CSV file
if (storage) filepath0 <- stringr::str_c("llm_output/", columnname, "/")
if (storage) if (!base::dir.exists(filepath0)) {
base::dir.create(filepath0, recursive = TRUE)
}
if (storage) filepath <- stringr::str_c(filepath0, model, ".csv")
if (storage) base::print(base::paste("Writing CSV file to:", filepath))
if (storage) utils::write.csv(data.frame(sys_prompt=sys_prompt,user_prompt=user_prompt,aitag = annotations), filepath, row.names = FALSE)
# Return the vector of annotations
return(annotations)
}
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- c("Apple", "Tomato", "Broccoli")
annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?",storage = FALSE)
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- c("Apple", "Tomato", "Broccoli")
annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?",storage = TRUE)
#' @examples
#' \dontrun{
#' my_data <- c("Apple", "Tomato", "Broccoli")
#' annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?")
#' }
#' @importFrom httr2 request req_headers req_body_json req_timeout req_perform resp_body_json
#' @importFrom stringr str_c str_replace_all
#' @importFrom dplyr if_else
#' @importFrom utils write.csv
#' @export
tag_gpt <- function(user_prompt,
sys_prompt = "",
temperature = 0,
api_key = base::Sys.getenv("openai_key"),
api_url = base::Sys.getenv("openai_url"),
model = "gpt-3.5-turbo-0125",
verbose = TRUE,
storage = TRUE,
rate_limit = 0.6) {
# Ensure the API URL is complete
api_url <- stringr::str_c(api_url, "/v1/chat/completions")
# Add filepath for output
columnname <- base::deparse(base::substitute(user_prompt))
# Function to process each text entry
annotate_text <- function(text, index, total) {
to_annotate_text <- stringr::str_replace_all(text, "(\n|\r)", " ")
authorization <- dplyr::if_else(api_url == "https://api.openai.com/v1/chat/completions", api_key, base::paste0("Bearer ", api_key))
attempt <- 1
max_attempts <- 3
success <- FALSE
result <- NA_character_
while (!success && attempt <= max_attempts) {
base::Sys.sleep(rate_limit) # Sleep to avoid rate limiting
tryCatch({
response <- httr2::request(api_url) |>
httr2::req_headers(`Content-Type` = "application/json", `Authorization` = authorization) |>
httr2::req_body_json(list(
model = model,
temperature = temperature,
messages = list(
list(role = "system", content = sys_prompt),
list(role = "user", content = to_annotate_text)
)
)) |>
httr2::req_timeout(60000) |> # 60 seconds timeout
httr2::req_perform()
if (response$status_code < 400) {
response_content <- httr2::resp_body_json(response)
result <- response_content$choices[[1]]$message$content
success <- TRUE
if (verbose) base::message("status_id: ", index, " of ", total, "\n", "sys_prompt: ", sys_prompt, "\n", "user_prompt: ", to_annotate_text)
if (verbose) base::message("ChatGPT: ", result, "\n")
} else {
# Capture and return the error message from the response
error_content <- httr2::resp_body_json(response)
result <- error_content$error$message
if (verbose) base::message(base::paste("Error annotating text", index, ":", result))
break
}
}, error = function(e) {
if (verbose) base::message(base::paste("Error on text", index, ":", e$message))
})
if (!success) {
attempt <- attempt + 1
if (verbose) base::message(base::paste("Retrying text", index, "- Attempt", attempt, "of", max_attempts))
}
}
if (!success && base::is.na(result)) {
result <- "An unknown error occurred."
if (verbose) base::message(base::paste("Failed to annotate text", index, "after", max_attempts, "attempts."))
}
return(result)
}
# Vectorize the function to process all entries in the column
annotations <- purrr::map2_chr(user_prompt, base::seq_along(user_prompt), ~annotate_text(.x, .y, base::length(user_prompt)))
# Write the results to a CSV file
if (storage) filepath0 <- stringr::str_c("llm_output/", columnname, "/")
if (storage) if (!base::dir.exists(filepath0)) {
base::dir.create(filepath0, recursive = TRUE)
}
if (storage) filepath <- stringr::str_c(filepath0, model, ".csv")
if (storage) base::print(base::paste("Writing CSV file to:", filepath))
if (storage) utils::write.csv(data.frame(sys_prompt=sys_prompt,user_prompt=user_prompt,aitag = annotations), filepath, row.names = FALSE)
# Return the vector of annotations
return(annotations)
}
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- c("Apple", "Tomato", "Broccoli")
annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?")
Sys.setenv("openai_key" = "sk-yafpZCQBmVWLtP0edcyZk3qQVjl3kTZHFB7GljZ6C3puly1L")
Sys.setenv("openai_url" = "https://api.chatanywhere.cn")
my_data <- c("Apple", "Tomato", "Broccoli")
annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?",rate_limit = 0.8)
annotated_data <- tag_gpt(my_data, sys_prompt = "Which one is a fruit?",rate_limit = 0.8)
devtools::check()
devtools::check()
